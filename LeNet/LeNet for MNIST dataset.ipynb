{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(numChannels, imgRows, imgCols, numClasses,\n",
    "\t\tactivation=\"relu\", weightsPath=None):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (imgRows, imgCols, numChannels)\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (numChannels, imgRows, imgCols)\n",
    "            \n",
    "\t\t# define the first set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Conv2D(20, 5, padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "\t\t# define the second set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Conv2D(50, 5, padding=\"same\"))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "\t\t# define the first FC => ACTIVATION layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\n",
    "\t\t# define the second FC layer\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\n",
    "\t\t# lastly, define the soft-max classifier\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "        \n",
    "\t\t# if a weights path is supplied (inicating that the model was\n",
    "\t\t# pre-trained), then load the weights\n",
    "\t\tif weightsPath is not None:\n",
    "\t\t\tmodel.load_weights(weightsPath)\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#from pyimagesearch.cnn.networks.lenet import LeNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] downloading MNIST...\n"
     ]
    }
   ],
   "source": [
    "# grab the MNIST dataset (if this is your first time running this\n",
    "# script, the download may take a minute -- the 55MB MNIST dataset\n",
    "# will be downloaded)\n",
    "print(\"[INFO] downloading MNIST...\")\n",
    "((trainData, trainLabels), (testData, testLabels)) = mnist.load_data()\n",
    "\n",
    "# if we are using \"channels first\" ordering, then reshape the\n",
    "# design matrix such that the matrix is:\n",
    "# num_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "\ttrainData = trainData.reshape((trainData.shape[0], 1, 28, 28))\n",
    "\ttestData = testData.reshape((testData.shape[0], 1, 28, 28))\n",
    "\n",
    "# otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "\ttrainData = trainData.reshape((trainData.shape[0], 28, 28, 1))\n",
    "\ttestData = testData.reshape((testData.shape[0], 28, 28, 1))\n",
    "\n",
    "# scale data to the range of [0, 1]\n",
    "trainData = trainData.astype(\"float32\") / 255.0\n",
    "testData = testData.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# transform the training and testing labels into vectors in the\n",
    "# range [0, classes] -- this generates a vector for each label,\n",
    "# where the index of the label is set to `1` and all other entries\n",
    "# to `0`; in the case of MNIST, there are 10 class labels\n",
    "trainLabels = np_utils.to_categorical(trainLabels, 10)\n",
    "testLabels = np_utils.to_categorical(testLabels, 10)\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.01)\n",
    "model = LeNet.build(numChannels=1, imgRows=28, imgCols=28,\n",
    "\tnumClasses=10,\n",
    "\tweightsPath= None)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training...\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 1.0117 - accuracy: 0.7393\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 136s 2ms/step - loss: 0.2553 - accuracy: 0.9238\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 136s 2ms/step - loss: 0.1779 - accuracy: 0.9480\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 138s 2ms/step - loss: 0.1393 - accuracy: 0.9590\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 139s 2ms/step - loss: 0.1158 - accuracy: 0.9658\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 138s 2ms/step - loss: 0.1001 - accuracy: 0.9703\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 138s 2ms/step - loss: 0.0886 - accuracy: 0.9737\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0807 - accuracy: 0.9757\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 215s 4ms/step - loss: 0.0726 - accuracy: 0.9780\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0671 - accuracy: 0.9796\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 212s 4ms/step - loss: 0.0636 - accuracy: 0.9806\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 0.0593 - accuracy: 0.9820\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 207s 3ms/step - loss: 0.0555 - accuracy: 0.9832\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 0.0524 - accuracy: 0.9842\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 0.0494 - accuracy: 0.9855\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0472 - accuracy: 0.9857\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 0.0451 - accuracy: 0.9863\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0432 - accuracy: 0.9868\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 0.0409 - accuracy: 0.9874\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0396 - accuracy: 0.9877\n",
      "[INFO] evaluating...\n",
      "10000/10000 [==============================] - 16s 2ms/step\n",
      "[INFO] accuracy: 98.72%\n"
     ]
    }
   ],
   "source": [
    "# only train and evaluate the model if we *are not* loading a\n",
    "# pre-existing model\n",
    "#if args[\"load_model\"] < 0:\n",
    "print(\"[INFO] training...\")\n",
    "model.fit(trainData, trainLabels, batch_size=128, epochs=20,\n",
    "\tverbose=1)\n",
    "\n",
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating...\")\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels,\n",
    "\tbatch_size=128, verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] dumping weights to file...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] dumping weights to file...\")\n",
    "model.save_weights(\"weights\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicted: 0, Actual: 0\n",
      "[INFO] Predicted: 3, Actual: 3\n",
      "[INFO] Predicted: 6, Actual: 6\n",
      "[INFO] Predicted: 1, Actual: 1\n",
      "[INFO] Predicted: 1, Actual: 1\n",
      "[INFO] Predicted: 9, Actual: 9\n",
      "[INFO] Predicted: 9, Actual: 9\n",
      "[INFO] Predicted: 9, Actual: 9\n",
      "[INFO] Predicted: 0, Actual: 0\n",
      "[INFO] Predicted: 3, Actual: 3\n"
     ]
    }
   ],
   "source": [
    "# randomly select a few testing digits\n",
    "for i in np.random.choice(np.arange(0, len(testLabels)), size=(10,)):\n",
    "\t# classify the digit\n",
    "\tprobs = model.predict(testData[np.newaxis, i])\n",
    "\tprediction = probs.argmax(axis=1)\n",
    "\t# extract the image from the testData if using \"channels_first\"\n",
    "\t# ordering\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\timage = (testData[i][0] * 255).astype(\"uint8\")\n",
    "\t# otherwise we are using \"channels_last\" ordering\n",
    "\telse:\n",
    "\t\timage = (testData[i] * 255).astype(\"uint8\")\n",
    "\t# merge the channels into one image\n",
    "\timage = cv2.merge([image] * 3)\n",
    "\t# resize the image from a 28 x 28 image to a 96 x 96 image so we\n",
    "\t# can better see it\n",
    "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "\t# show the image and prediction\n",
    "\tcv2.putText(image, str(prediction[0]), (5, 20),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\tprint(\"[INFO] Predicted: {}, Actual: {}\".format(prediction[0],\n",
    "\t\tnp.argmax(testLabels[i])))\n",
    "\tcv2.imshow(\"Digit\", image)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
